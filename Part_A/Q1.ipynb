{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06dd4aaf-c1aa-4e29-b4ef-6b79e3c05524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77193a2d-d2d7-4c97-af33-1779ed45ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (activation): GELU(approximate='none')\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): GELU(approximate='none')\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): GELU(approximate='none')\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4608, out_features=10, bias=True)\n",
      "    (2): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_lightning import LightningModule\n",
    "import random\n",
    "\n",
    "class CNN(LightningModule):\n",
    "    def __init__(self,in_channels,num_filters_conv, filter_sizes_conv, num_filters_dense ,activation='relu' ):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Select the activation function\n",
    "        if activation == 'relu':\n",
    "            self.acitvation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        elif activation == 'elu':\n",
    "            self.activation  = nn.ELU()\n",
    "        else:\n",
    "            self.activation = nn.SiLU()\n",
    "            \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=num_filters_conv[0], kernel_size=filter_sizes_conv[0],stride=1, padding=1),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_filters_conv[0], out_channels=num_filters_conv[1], kernel_size=filter_sizes_conv[1],stride =1 , padding=1),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_filters_conv[1], out_channels=num_filters_conv[2], kernel_size=filter_sizes_conv[2],stride=1, padding=1),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_filters_conv[2], out_channels=num_filters_conv[3], kernel_size=filter_sizes_conv[3],stride=1, padding=1),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_filters_conv[3], out_channels=num_filters_conv[4], kernel_size=filter_sizes_conv[4],stride=1, padding=1),\n",
    "            self.activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=num_filters_conv[-1]*3*3, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.dense_layers(x)\n",
    "        return x\n",
    "\n",
    "# Assuming the use of PyTorch Lightning for training setup\n",
    "class LitCNN(CNN):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "in_channels = 3  # For RGB images\n",
    "num_filters_conv=[32, 64, 128, 256, 512]\n",
    "filter_sizes_conv=[3, 3, 3, 3, 3]\n",
    "num_filters_dense=[1024]\n",
    "activation = random.choice(['relu','tanh','sigmoid','gelu', 'elu', 'silu'])\n",
    "model = CNN(in_channels,num_filters_conv, filter_sizes_conv,num_filters_dense,activation)\n",
    "print(model)\n",
    "# Note: You'll need to define your data loaders and training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6d0b4-ebd0-4d52-bcc0-ba858191dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9497db-5304-4905-8b11-c22a4e5b5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade wandb\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.empty_cache()\n",
    "from torch import  nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.common import flatten\n",
    "from tqdm import tqdm \n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63313dc8-7f71-4e63-8363-e4794cdaa7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://wandb.ai/\" \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\" -c -O 'nature_12K.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92ff14d1-1d29-465c-bfc4-f9e114e1de06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "!unzip \"nature_12K.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b07b2c-4832-48d9-bec8-ab335a4f2653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def check_os():\n",
    "    if os.name == 'nt':\n",
    "        return 'Windows'\n",
    "    else:\n",
    "        return 'Linux'\n",
    "operatingSystem = check_os()\n",
    "# print(operatingSystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383824d0-8542-40e8-b20a-82e0a1502d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom dataset class for inaturalist dataset\n",
    "class iNaturalist(Dataset):\n",
    "    def __init__(self, image_paths, class_to_idx, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.class_to_idx= class_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.cvtColor(cv2.imread(image_filepath), cv2.COLOR_BGR2RGB)\n",
    "        # print(image_filepath)\n",
    "        if(operatingSystem=='Windows'):\n",
    "            label = image_filepath.split('\\\\')[-2]\n",
    "        else:\n",
    "            label = image_filepath.split('/')[-2]\n",
    "        # print(label)\n",
    "        label = self.class_to_idx[label]\n",
    "        \n",
    "        PIL_image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        PIL_image = self.transform(PIL_image)\n",
    "\n",
    "        return PIL_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c701a3-788e-48a5-8d58-afa847d16047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSlash(l):\n",
    "    a=[]\n",
    "    for ele in l:\n",
    "        a.append(ele.replace('\\\\','/'))\n",
    "    return a\n",
    "    \n",
    "def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n",
    "    #Defining transformations when data_aug=True  [used when data_type='train' and data_aug=True]\n",
    "    if(data_aug):\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                              T.RandomRotation(degrees=15),\n",
    "                              T.RandomHorizontalFlip(p=0.5),\n",
    "                              T.RandomGrayscale(p=0.2),\n",
    "                              T.ToTensor()])\n",
    "    else:\n",
    "    #Defining transformations when data_aug=False\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "    image_paths=[] # List to store image paths\n",
    "    classes= [] # List to  store class values\n",
    "    #get all the paths from data_path and append image paths and class to to respective lists\n",
    "    cnt=0\n",
    "    for curr_data_path in glob.glob(data_path + '/*'):\n",
    "        if(operatingSystem=='Windows'):\n",
    "            classes.append(curr_data_path.split('\\\\')[-1])\n",
    "        else:\n",
    "            classes.append(curr_data_path.split('/')[-1])\n",
    "        image_paths.append(glob.glob(curr_data_path+'/*'))\n",
    "    image_paths = list(flatten(image_paths))\n",
    "    # image_paths = forwardSlash(image_paths)\n",
    "    #Creating dictionary for class indexes\n",
    "    idx_to_class={}\n",
    "    class_to_idx={}\n",
    "    for i in range(len(classes)):\n",
    "        idx=i\n",
    "        cls=classes[i]\n",
    "        idx_to_class[idx]=cls\n",
    "        class_to_idx[cls]=idx\n",
    "    # idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "    # for k in idx_to_class:\n",
    "        # v=idx_to_class[k]\n",
    "        # class_to_idx[v]=k\n",
    "    # class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "    if (data_type != 'test'):\n",
    "        random.shuffle(image_paths)\n",
    "        # 80% training data and 20% validation data\n",
    "        train_image_paths = image_paths[:int(0.8*len(image_paths))]\n",
    "        valid_image_paths = image_paths[int(0.8*len(image_paths)):] \n",
    "        #Using custom class for getting train and validation dataset\n",
    "        # if data_aug == True:\n",
    "        train_dataset = iNaturalist(train_image_paths,class_to_idx,transforms)\n",
    "        validation_dataset = iNaturalist(valid_image_paths,class_to_idx,transforms)  \n",
    "        # else:\n",
    "        #     train_dataset = iNaturalist(train_image_paths,class_to_idx,false_transforms)\n",
    "        #     valid_dataset = iNaturalist(valid_image_paths,class_to_idx,false_transforms)  \n",
    "        #using Dataloader to load train and valid dataset according to batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=b_size, shuffle=True)\n",
    "        return train_loader,validation_loader\n",
    "    else:\n",
    "        # test_image_paths=image_paths\n",
    "        #Using custom class for getting test dataset\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "        test_dataset= iNaturalist(image_paths,class_to_idx,transforms)\n",
    "        #using Dataloader to load test dataset according to batch size\n",
    "        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n",
    "        return test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ffb6e7-77b6-4955-a891-42f61bab5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "class ConvolutionBlocks(LightningModule):\n",
    "    def __init__(self, activation, batch_norm, size_filters, filter_organization, number_filters):\n",
    "        super(ConvolutionBlocks, self).__init__()\n",
    "        \n",
    "        self.activation=activation\n",
    "        self.num_filters=[number_filters]\n",
    "        self.batch_norm=batch_norm\n",
    "        \n",
    "        for i in range(1,5):\n",
    "          self.num_filters.append(int(self.num_filters[i-1]*filter_organization))\n",
    "            \n",
    "        if(self.batch_norm):  \n",
    "            self.conv_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[0]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "                \n",
    "                nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[1]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[2]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[3]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[4]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "            )\n",
    "        else:\n",
    "            self.conv_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "                \n",
    "                nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "            )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f37344-01bb-479e-a68a-3370bc16ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, number_initial_filters , neurons_in_dense_layer, image_shape,dropout , activation, batch_norm, size_filters, filter_organization):\n",
    "        super().__init__()\n",
    "        \n",
    "        if(activation=='relu'):\n",
    "            self.activation = nn.ReLU()\n",
    "        elif(activation=='gelu'):\n",
    "            self.activation = nn.GELU()\n",
    "        elif(activation=='silu'):\n",
    "            self.activation = nn.SiLU()\n",
    "        else:\n",
    "            self.activation = nn.Mish()\n",
    "            \n",
    "\n",
    "        self.conv_blocks = ConvolutionBlocks(self.activation, batch_norm, size_filters, filter_organization, number_initial_filters)\n",
    "        sz=self.conv_blocks(torch.zeros(*(image_shape))).data.shape\n",
    "        fc1_in_channels = sz[1] * sz[2] * sz[3]\n",
    "        self.output= nn.Linear(neurons_in_dense_layer,10,bias=True)   \n",
    "\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(fc1_in_channels,neurons_in_dense_layer,bias=True),\n",
    "            self.activation,\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = self.dense_layers(x)\n",
    "        x = F.softmax(self.output(x),dim=1) #Applying softmax across rows\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a746e577-b201-418b-bc3f-7e32e5c755b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(data,device,model,criterion):\n",
    "    loss=0\n",
    "    corr_sample=0\n",
    "    tot_sample=0\n",
    "    for x,y in tqdm(data,total=len(data)):\n",
    "        x=x.to(device=device)\n",
    "        y=y.to(device=device)\n",
    "        out = model(x)\n",
    "        loss+=criterion(out,y).item()\n",
    "        _,pred=out.max(1)\n",
    "        corr_sample+=(pred==y).sum().item()\n",
    "        tot_sample+=pred.size(0)\n",
    "    return corr_sample,tot_sample,loss\n",
    "    \n",
    "def evaluate(device, loader, model):\n",
    "    ''' Function to calculate accuracy to see performance of our model '''\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct_samples,total_samples,loss=0,0,0\n",
    "    with torch.no_grad():\n",
    "        correct_samples_,total_samples_,loss_ = cal(loader,device,model,criterion)\n",
    "        correct_samples+=correct_samples_\n",
    "        total_samples+=total_samples_\n",
    "        loss+=loss_\n",
    "           \n",
    "    acc = round((correct_samples / total_samples) * 100, 4)\n",
    "    return acc, loss/total_samples \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd4d745-14b0-40f4-bb05-c2fe979d3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_train(data,device,model,criterion,optimizer):\n",
    "    train_loss=0\n",
    "    corr_train=0\n",
    "    tot_sample=0\n",
    "    for idd,(x,y) in enumerate(tqdm(data)):\n",
    "        x=x.to(device=device)\n",
    "        yt=y.to(device=device)\n",
    "        out = model(x)\n",
    "        loss=criterion(out,yt)\n",
    "        train_loss+=loss.item()\n",
    "        _,pred=out.max(1)\n",
    "        corr_train+=(pred==yt).sum()\n",
    "        tot_sample+=pred.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return train_loss,tot_sample,corr_train\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    torch.cuda.empty_cache()\n",
    "    image_shape = (1,3,224,224) # All the images of dataset will get resized to this image shape\n",
    "    test_data_path = 'inaturalist_12K/val/'\n",
    "    train_data_path = 'inaturalist_12K/train/'\n",
    "     \n",
    "    wandb.run.name = 'ep-'+str(args.epochs)+'-lr-'+str(args.learning_rate)+'-bs-'+str(args.batch_size)+'-act-'+str(args.activation)+'-filter_sizes-'+str(args.size_filters) +'-ini_filt'+str(args.number_initial_filters)+'-n_d-'+str(args.neurons_in_dense_layer)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #CNN Model creation\n",
    "    model = Model(args.number_initial_filters ,args.neurons_in_dense_layer,image_shape,args.dropout, args.activation, args.batch_norm, args.size_filters, args.filter_organization).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # Train Network\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        test_loader = create_data(\"test\",test_data_path,args.data_aug, image_shape[2:], args.batch_size)\n",
    "        train_loader, valid_loader = create_data(\"train\",train_data_path,args.data_aug,image_shape[2:], args.batch_size)\n",
    "        \n",
    "        train_loss,total_samples,train_correct = cal_train(train_loader,device,model,criterion,optimizer)\n",
    "        # Calculating training accuracy and training loss\n",
    "        train_loss /= total_samples\n",
    "        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Calculating accuracy and loss for test and validataion data\n",
    "        val_acc, val_loss = evaluate(device, valid_loader, model)\n",
    "        test_acc, test_loss = evaluate(device, test_loader, model)\n",
    "\n",
    "        \n",
    "        #logging wandb data\n",
    "        wandb.log(\n",
    "          {'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc, 'train_loss': train_loss, 'val_loss': val_loss, 'test_loss': test_loss}\n",
    "        )\n",
    "        print('\\nEpoch ', epoch, 'train_acc', train_acc, 'val_acc', val_acc, 'test_acc', test_acc, 'train_loss', train_loss, 'val_loss', val_loss, 'test_loss', test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a485f2d9-9a99-4a52-8f93-8bb471a8fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m055\u001b[0m (\u001b[33mcs23m055_assignment_1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ravis\\.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: uxe0iw1a\n",
      "Sweep URL: https://wandb.ai/cs23m055/Assigment2_local/sweeps/uxe0iw1a\n",
      "sweep_id:  uxe0iw1a\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key = \"67fcf10073b0d1bfeee44a1e4bd6f3eb5b674f8e\")\n",
    "sweep_config = {\n",
    "    \"name\" : \"Assignment2_local\",\n",
    "    \"method\" : \"bayes\",\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        \"batch_norm\": {\n",
    "              \"values\": [True,False]\n",
    "        },\n",
    "        \"neurons_in_dense_layer\": {\n",
    "              \"values\": [32, 64, 128, 256, 512, 1024]\n",
    "          },\n",
    "        \"epochs\" : {\n",
    "            \"values\" : [5,8,10]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"data_aug\": {\n",
    "              \"values\": [True,False]\n",
    "        },\n",
    "        'size_filters':{\n",
    "            'values': [[7,5,5,3,3], [11,9,7,5,3]]\n",
    "        },\n",
    "        'filter_organization': {\n",
    "            'values': [1, 2, 0.5]\n",
    "        },\n",
    "        'number_initial_filters': {\n",
    "            'values': [16, 32, 64, 128]\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'mish', 'gelu', 'silu]\n",
    "        },\n",
    "        'learning_rate':{\n",
    "            \"values\": [0.001,0.0001,0.0003,0.0005]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0,0.1,0.2,0.3]\n",
    "        }        \n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Assigment2_local\", entity=\"cs23m055\")\n",
    "print('sweep_id: ', sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7786c633-554d-4f59-ae1b-469855b76127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_fn():\n",
    "      with wandb.init(project=\"Assignment2_local\", entity=\"cs23m055\") as run:\n",
    "        config = wandb.config\n",
    "        train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae97c2a9-6a66-4eaa-98c9-f648024f7694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e5iw86xj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneurons_in_dense_layer: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_initial_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_filters: [7, 5, 5, 3, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m055\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>M:\\Practice\\Semester-2\\Deep Learning\\Assignments\\Assignement 2\\Part_A\\wandb\\run-20240406_053146-e5iw86xj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs23m055/Assigment2_local/runs/e5iw86xj' target=\"_blank\">leafy-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m055/Assigment2_local' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m055/Assigment2_local/sweeps/uxe0iw1a' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local/sweeps/uxe0iw1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs23m055/Assigment2_local' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs23m055/Assigment2_local/sweeps/uxe0iw1a' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local/sweeps/uxe0iw1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs23m055/Assigment2_local/runs/e5iw86xj' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local/runs/e5iw86xj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [05:00<00:00,  1.20s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:17<00:00,  1.24s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:17<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0 train_acc 23.2529 val_acc 23.65 test_acc 25.65 train_loss 0.06919991944727115 val_loss 0.06953782236576081 test_loss 0.06907254886627197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [05:15<00:00,  1.26s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:18<00:00,  1.25s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:18<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1 train_acc 27.3159 val_acc 24.45 test_acc 24.9 train_loss 0.06803040132476086 val_loss 0.06937076210975647 test_loss 0.06924087285995484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [05:05<00:00,  1.22s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:19<00:00,  1.26s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:20<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2 train_acc 30.4413 val_acc 28.25 test_acc 30.4 train_loss 0.06716327415971342 val_loss 0.06838828068971634 test_loss 0.06776764488220215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [05:12<00:00,  1.25s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:20<00:00,  1.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:20<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3 train_acc 31.3664 val_acc 32.2 test_acc 28.7 train_loss 0.06682003758999538 val_loss 0.06714371037483215 test_loss 0.068160549223423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [05:17<00:00,  1.27s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:19<00:00,  1.26s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  4 train_acc 32.4666 val_acc 32.25 test_acc 31.2 train_loss 0.06645569030546161 val_loss 0.06691086000204086 test_loss 0.06742456823587417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▂▁▇▅█</td></tr><tr><td>test_loss</td><td>▇█▂▄▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_acc</td><td>▁▂▅██</td></tr><tr><td>val_loss</td><td>██▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>31.2</td></tr><tr><td>test_loss</td><td>0.06742</td></tr><tr><td>train_acc</td><td>32.4666</td></tr><tr><td>train_loss</td><td>0.06646</td></tr><tr><td>val_acc</td><td>32.25</td></tr><tr><td>val_loss</td><td>0.06691</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-1</strong> at: <a href='https://wandb.ai/cs23m055/Assigment2_local/runs/e5iw86xj' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local/runs/e5iw86xj</a><br/> View project at: <a href='https://wandb.ai/cs23m055/Assigment2_local' target=\"_blank\">https://wandb.ai/cs23m055/Assigment2_local</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240406_053146-e5iw86xj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=spawn_fn, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a4e1d-784d-4270-9109-f7aef585f43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
