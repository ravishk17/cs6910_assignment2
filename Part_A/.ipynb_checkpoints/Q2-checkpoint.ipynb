{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c3f564-3a55-43ff-b54d-fa33beaaad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inaturalist_12K1\\train\n",
      "inaturalist_12K1\\val\n"
     ]
    }
   ],
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6415867-ef3c-4ae6-95bb-8400c70328a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System: Windows\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade wandb\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.empty_cache()\n",
    "from torch import  nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.common import flatten\n",
    "from tqdm import tqdm \n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6bd76-968f-45ac-b865-9a14823bfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://wandb.ai/\" \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\" -c -O 'nature_12K.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2d7e1-0d03-47d3-aa50-ee605e9e78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"nature_12K.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931059d8-313f-4789-a333-139bc878e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def check_os():\n",
    "    if os.name == 'nt':\n",
    "        return 'Windows'\n",
    "    else:\n",
    "        return 'Linux'\n",
    "operatingSystem = check_os()\n",
    "# print(operatingSystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8279d-b592-48b7-a652-857818197079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom dataset class for inaturalist dataset\n",
    "class iNaturalist(Dataset):\n",
    "    def __init__(self, image_paths, class_to_idx, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.class_to_idx= class_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.cvtColor(cv2.imread(image_filepath), cv2.COLOR_BGR2RGB)\n",
    "        # print(image_filepath)\n",
    "        if(operatingSystem=='Windows'):\n",
    "            label = image_filepath.split('\\\\')[-2]\n",
    "        else:\n",
    "            label = image_filepath.split('/')[-2]\n",
    "        # print(label)\n",
    "        label = self.class_to_idx[label]\n",
    "        \n",
    "        PIL_image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        PIL_image = self.transform(PIL_image)\n",
    "\n",
    "        return PIL_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e326e-da18-4ff7-b7e3-e572f4bc1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSlash(l):\n",
    "    a=[]\n",
    "    for ele in l:\n",
    "        a.append(ele.replace('\\\\','/'))\n",
    "    return a\n",
    "    \n",
    "def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n",
    "    #Defining transformations when data_aug=True  [used when data_type='train' and data_aug=True]\n",
    "    if(data_aug):\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                              T.RandomRotation(degrees=15),\n",
    "                              T.RandomHorizontalFlip(p=0.5),\n",
    "                              T.RandomGrayscale(p=0.2),\n",
    "                              T.ToTensor()])\n",
    "    else:\n",
    "    #Defining transformations when data_aug=False\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "    image_paths=[] # List to store image paths\n",
    "    classes= [] # List to  store class values\n",
    "    #get all the paths from data_path and append image paths and class to to respective lists\n",
    "    cnt=0\n",
    "    for curr_data_path in glob.glob(data_path + '/*'):\n",
    "        if(operatingSystem=='Windows'):\n",
    "            classes.append(curr_data_path.split('\\\\')[-1])\n",
    "        else:\n",
    "            classes.append(curr_data_path.split('/')[-1])\n",
    "        image_paths.append(glob.glob(curr_data_path+'/*'))\n",
    "    image_paths = list(flatten(image_paths))\n",
    "    # image_paths = forwardSlash(image_paths)\n",
    "    #Creating dictionary for class indexes\n",
    "    idx_to_class={}\n",
    "    class_to_idx={}\n",
    "    for i in range(len(classes)):\n",
    "        idx=i\n",
    "        cls=classes[i]\n",
    "        idx_to_class[idx]=cls\n",
    "        class_to_idx[cls]=idx\n",
    "    # idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "    # for k in idx_to_class:\n",
    "        # v=idx_to_class[k]\n",
    "        # class_to_idx[v]=k\n",
    "    # class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "    if (data_type != 'test'):\n",
    "        random.shuffle(image_paths)\n",
    "        # 80% training data and 20% validation data\n",
    "        train_image_paths = image_paths[:int(0.8*len(image_paths))]\n",
    "        valid_image_paths = image_paths[int(0.8*len(image_paths)):] \n",
    "        #Using custom class for getting train and validation dataset\n",
    "        # if data_aug == True:\n",
    "        train_dataset = iNaturalist(train_image_paths,class_to_idx,transforms)\n",
    "        validation_dataset = iNaturalist(valid_image_paths,class_to_idx,transforms)  \n",
    "        # else:\n",
    "        #     train_dataset = iNaturalist(train_image_paths,class_to_idx,false_transforms)\n",
    "        #     valid_dataset = iNaturalist(valid_image_paths,class_to_idx,false_transforms)  \n",
    "        #using Dataloader to load train and valid dataset according to batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=b_size, shuffle=True)\n",
    "        return train_loader,validation_loader\n",
    "    else:\n",
    "        # test_image_paths=image_paths\n",
    "        #Using custom class for getting test dataset\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "        test_dataset= iNaturalist(image_paths,class_to_idx,transforms)\n",
    "        #using Dataloader to load test dataset according to batch size\n",
    "        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n",
    "        return test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464e346-6f7e-4623-bba3-6d956425730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "class ConvolutionBlocks(LightningModule):\n",
    "    def __init__(self, activation, batch_norm, size_filters, filter_organization, number_filters):\n",
    "        super(ConvolutionBlocks, self).__init__()\n",
    "        \n",
    "        self.activation=activation\n",
    "        self.num_filters=[number_filters]\n",
    "        self.batch_norm=batch_norm\n",
    "        \n",
    "        for i in range(1,5):\n",
    "          self.num_filters.append(int(self.num_filters[i-1]*filter_organization))\n",
    "            \n",
    "        if(self.batch_norm):  \n",
    "            self.conv_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[0]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "                \n",
    "                nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[1]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[2]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[3]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                nn.BatchNorm2d(self.num_filters[4]),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "            )\n",
    "        else:\n",
    "            self.conv_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "                \n",
    "                nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    \n",
    "                nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False),\n",
    "                self.activation,\n",
    "                nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "            )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa745b44-97dc-4065-ba3b-22c63c9f7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, number_initial_filters , neurons_in_dense_layer, image_shape,dropout , activation, batch_norm, size_filters, filter_organization):\n",
    "        super().__init__()\n",
    "        \n",
    "        if(activation=='relu'):\n",
    "            self.activation = nn.ReLU()\n",
    "        elif(activation=='gelu'):\n",
    "            self.activation = nn.GELU()\n",
    "        elif(activation=='silu'):\n",
    "            self.activation = nn.SiLU()\n",
    "        else:\n",
    "            self.activation = nn.Mish()\n",
    "            \n",
    "\n",
    "        self.conv_blocks = ConvolutionBlocks(self.activation, batch_norm, size_filters, filter_organization, number_initial_filters)\n",
    "        sz=self.conv_blocks(torch.zeros(*(image_shape))).data.shape\n",
    "        fc1_in_channels = sz[1] * sz[2] * sz[3]\n",
    "        self.output= nn.Linear(neurons_in_dense_layer,10,bias=True)   \n",
    "\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(fc1_in_channels,neurons_in_dense_layer,bias=True),\n",
    "            self.activation,\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = self.dense_layers(x)\n",
    "        x = F.softmax(self.output(x),dim=1) #Applying softmax across rows\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43663c7d-1ae8-401e-b470-abfbec4cb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(data,device,model,criterion):\n",
    "    loss=0\n",
    "    corr_sample=0\n",
    "    tot_sample=0\n",
    "    for x,y in tqdm(data,total=len(data)):\n",
    "        x=x.to(device=device)\n",
    "        y=y.to(device=device)\n",
    "        out = model(x)\n",
    "        loss+=criterion(out,y).item()\n",
    "        _,pred=out.max(1)\n",
    "        corr_sample+=(pred==y).sum().item()\n",
    "        tot_sample+=pred.size(0)\n",
    "    return corr_sample,tot_sample,loss\n",
    "    \n",
    "def evaluate(device, loader, model):\n",
    "    ''' Function to calculate accuracy to see performance of our model '''\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct_samples,total_samples,loss=0,0,0\n",
    "    with torch.no_grad():\n",
    "        correct_samples_,total_samples_,loss_ = cal(loader,device,model,criterion)\n",
    "        correct_samples+=correct_samples_\n",
    "        total_samples+=total_samples_\n",
    "        loss+=loss_\n",
    "           \n",
    "    acc = round((correct_samples / total_samples) * 100, 4)\n",
    "    return acc, loss/total_samples \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b59db1-ba93-4435-807f-61ae2c83f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_train(data,device,model,criterion,optimizer):\n",
    "    train_loss=0\n",
    "    corr_train=0\n",
    "    tot_sample=0\n",
    "    for idd,(x,y) in enumerate(tqdm(data)):\n",
    "        x=x.to(device=device)\n",
    "        yt=y.to(device=device)\n",
    "        out = model(x)\n",
    "        loss=criterion(out,yt)\n",
    "        train_loss+=loss.item()\n",
    "        _,pred=out.max(1)\n",
    "        corr_train+=(pred==yt).sum()\n",
    "        tot_sample+=pred.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return train_loss,tot_sample,corr_train\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    torch.cuda.empty_cache()\n",
    "    image_shape = (1,3,224,224) # All the images of dataset will get resized to this image shape\n",
    "    test_data_path = 'inaturalist_12K/val/'\n",
    "    train_data_path = 'inaturalist_12K/train/'\n",
    "     \n",
    "    wandb.run.name = 'ep-'+str(args.epochs)+'-lr-'+str(args.learning_rate)+'-bs-'+str(args.batch_size)+'-act-'+str(args.activation)+'-filter_sizes-'+str(args.size_filters) +'-ini_filt'+str(args.number_initial_filters)+'-n_d-'+str(args.neurons_in_dense_layer)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #CNN Model creation\n",
    "    model = Model(args.number_initial_filters ,args.neurons_in_dense_layer,image_shape,args.dropout, args.activation, args.batch_norm, args.size_filters, args.filter_organization).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # Train Network\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        test_loader = create_data(\"test\",test_data_path,args.data_aug, image_shape[2:], args.batch_size)\n",
    "        train_loader, valid_loader = create_data(\"train\",train_data_path,args.data_aug,image_shape[2:], args.batch_size)\n",
    "        \n",
    "        train_loss,total_samples,train_correct = cal_train(train_loader,device,model,criterion,optimizer)\n",
    "        # Calculating training accuracy and training loss\n",
    "        train_loss /= total_samples\n",
    "        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Calculating accuracy and loss for test and validataion data\n",
    "        val_acc, val_loss = evaluate(device, valid_loader, model)\n",
    "        test_acc, test_loss = evaluate(device, test_loader, model)\n",
    "\n",
    "        \n",
    "        #logging wandb data\n",
    "        wandb.log(\n",
    "          {'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc, 'train_loss': train_loss, 'val_loss': val_loss, 'test_loss': test_loss}\n",
    "        )\n",
    "        print('\\nEpoch ', epoch, 'train_acc', train_acc, 'val_acc', val_acc, 'test_acc', test_acc, 'train_loss', train_loss, 'val_loss', val_loss, 'test_loss', test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1943e85-5599-46f2-846f-11b18c3d6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key = \"67fcf10073b0d1bfeee44a1e4bd6f3eb5b674f8e\")\n",
    "sweep_config = {\n",
    "    \"name\" : \"Assignment2_local\",\n",
    "    \"method\" : \"bayes\",\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        \"batch_norm\": {\n",
    "              \"values\": [True,False]\n",
    "        },\n",
    "        \"neurons_in_dense_layer\": {\n",
    "              \"values\": [32, 64, 128, 256, 512, 1024]\n",
    "          },\n",
    "        \"epochs\" : {\n",
    "            \"values\" : [5,8,10]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"data_aug\": {\n",
    "              \"values\": [True,False]\n",
    "        },\n",
    "        'size_filters':{\n",
    "            'values': [[7,5,5,3,3], [11,9,7,5,3]]\n",
    "        },\n",
    "        'filter_organization': {\n",
    "            'values': [1, 2, 0.5]\n",
    "        },\n",
    "        'number_initial_filters': {\n",
    "            'values': [16, 32, 64, 128]\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'mish', 'gelu', 'silu]\n",
    "        },\n",
    "        'learning_rate':{\n",
    "            \"values\": [0.001,0.0001,0.0003,0.0005]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0,0.1,0.2,0.3]\n",
    "        }        \n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Assigment2_local\", entity=\"cs23m055\")\n",
    "print('sweep_id: ', sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd1387-693d-43b1-86c2-dc89313085ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_fn():\n",
    "      with wandb.init(project=\"Assignment2_local\", entity=\"cs23m055\") as run:\n",
    "        config = wandb.config\n",
    "        train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd33955-8a77-4fa4-a045-10e20c9c9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=spawn_fn, count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
