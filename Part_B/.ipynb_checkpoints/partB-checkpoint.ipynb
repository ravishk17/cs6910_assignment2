{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbf178f-7acf-47dd-97d1-1347717a4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade wandb\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import googlenet\n",
    "import glob\n",
    "from pandas.core.common import flatten\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9582b5-4c9f-4623-b513-2b1a91fedb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def check_os():\n",
    "    if os.name == 'nt':\n",
    "        return 'Windows'\n",
    "    else:\n",
    "        return 'Linux'\n",
    "operatingSystem = check_os()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581dd35a-54f5-452c-a827-4a0d638f4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom dataset class for inaturalist dataset\n",
    "from PIL import Image\n",
    "\n",
    "def numpy_to_pil(image):\n",
    "    return Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "    \n",
    "class iNaturalist(Dataset):\n",
    "    def __init__(self, image_paths, class_to_idx, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.class_to_idx= class_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.cvtColor(cv2.imread(image_filepath), cv2.COLOR_BGR2RGB)\n",
    "        # print(image_filepath)\n",
    "        if(operatingSystem=='Windows'):\n",
    "            label = image_filepath.split('\\\\')[-2]\n",
    "        else:\n",
    "            label = image_filepath.split('/')[-2]\n",
    "        # print(label)\n",
    "        label = self.class_to_idx[label]\n",
    "        \n",
    "        PIL_image = numpy_to_pil(image)\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        PIL_image = self.transform(PIL_image)\n",
    "\n",
    "        return PIL_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da1d897-aa48-4914-bd92-a629a368b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n",
    "    #Defining transformations when data_aug=True  [used when data_type='train' and data_aug=True]\n",
    "    if(data_aug):\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                              T.RandomRotation(degrees=15),\n",
    "                              T.RandomHorizontalFlip(p=0.5),\n",
    "                              T.RandomGrayscale(p=0.2),\n",
    "                              T.ToTensor()])\n",
    "    else:\n",
    "    #Defining transformations when data_aug=False\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "    image_paths=[] # List to store image paths\n",
    "    classes= [] # List to  store class values\n",
    "    #get all the paths from data_path and append image paths and class to to respective lists\n",
    "    cnt=0\n",
    "    for curr_data_path in glob.glob(data_path + '/*'):\n",
    "        if(operatingSystem=='Windows'):\n",
    "            classes.append(curr_data_path.split('\\\\')[-1])\n",
    "        else:\n",
    "            classes.append(curr_data_path.split('/')[-1])\n",
    "        image_paths.append(glob.glob(curr_data_path+'/*'))\n",
    "    image_paths = list(flatten(image_paths))\n",
    "    \n",
    "    #Creating dictionary for class indexes\n",
    "    idx_to_class={}\n",
    "    class_to_idx={}\n",
    "    for i in range(len(classes)):\n",
    "        idx=i\n",
    "        cls=classes[i]\n",
    "        idx_to_class[idx]=cls\n",
    "        class_to_idx[cls]=idx\n",
    "    \n",
    "    if (data_type != 'test'):\n",
    "        random.shuffle(image_paths)\n",
    "        # 80% training data and 20% validation data\n",
    "        train_image_paths = image_paths[:int(0.8*len(image_paths))]\n",
    "        valid_image_paths = image_paths[int(0.8*len(image_paths)):] \n",
    "        #Using custom class for getting train and validation dataset\n",
    "        \n",
    "        train_dataset = iNaturalist(train_image_paths,class_to_idx,transforms)\n",
    "        validation_dataset = iNaturalist(valid_image_paths,class_to_idx,transforms)  \n",
    "          \n",
    "        #using Dataloader to load train and valid dataset according to batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=b_size, shuffle=True)\n",
    "        return train_loader,validation_loader\n",
    "    else:\n",
    "        #Using custom class for getting test dataset\n",
    "        transforms = T.Compose([T.Resize((image_shape)),\n",
    "                               T.ToTensor()])\n",
    "        test_dataset= iNaturalist(image_paths,class_to_idx,transforms)\n",
    "        #using Dataloader to load test dataset according to batch size\n",
    "        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a72991-0e14-450a-b188-9fbdd5963a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(data,device,model,criterion):\n",
    "    loss=0\n",
    "    corr_sample=0\n",
    "    tot_sample=0\n",
    "    for x,y in tqdm(data,total=len(data)):\n",
    "        x=x.to(device=device)\n",
    "        y=y.to(device=device)\n",
    "        out = model(x)\n",
    "        loss+=criterion(out,y).item()\n",
    "        _,pred=out.max(1)\n",
    "        corr_sample+=(pred==y).sum().item()\n",
    "        tot_sample+=pred.size(0)\n",
    "    return corr_sample,tot_sample,loss\n",
    "    \n",
    "def evaluate(device, loader, model):\n",
    "    ''' Function to calculate accuracy to see performance of our model '''\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct_samples,total_samples,loss=0,0,0\n",
    "    with torch.no_grad():\n",
    "        correct_samples_,total_samples_,loss_ = cal(loader,device,model,criterion)\n",
    "        correct_samples+=correct_samples_\n",
    "        total_samples+=total_samples_\n",
    "        loss+=loss_\n",
    "           \n",
    "    acc = round((correct_samples / total_samples) * 100, 4)\n",
    "    return acc, loss/total_samples \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07d872c-d8b4-4d1e-b02a-f76c4043e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_train(data,device,model,criterion,optimizer):\n",
    "    train_loss=0\n",
    "    corr_train=0\n",
    "    tot_sample=0\n",
    "    for idd,(x,y) in enumerate(tqdm(data)):\n",
    "        x=x.to(device=device)\n",
    "        yt=y.to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss=criterion(out,yt) \n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = torch.max(out, 1) \n",
    "        corr_train+=(pred==yt).sum()\n",
    "        tot_sample+=pred.size(0)\n",
    "    return train_loss,tot_sample,corr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cae52c-4532-48b3-a5dd-bfadfcf5c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ravis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import googlenet\n",
    "model = googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f8730f-659c-4be5-9730-59a5a8f05e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fine_tune(model,epochs=5,strategy=0):\n",
    "    if strategy == 0:\n",
    "        # Freeze all layers except the final classification layer\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    elif strategy == 1:\n",
    "        # Unfreeze all layers and train the entire model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif strategy == 2:\n",
    "        # Unfreeze and fine-tune only a subset of layers (e.g., only top layers)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in model.inception5b.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "    image_shape = (1,3,224,224) # All the images of dataset will get resized to this image shape\n",
    "    test_data_path = 'inaturalist_12K/val/'\n",
    "    train_data_path = 'inaturalist_12K/train/'\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.00001)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # test_loader = create_data(\"test\",test_data_path,args.data_aug, image_shape[2:], args.batch_size)\n",
    "        train_loader, valid_loader = create_data(\"train\",train_data_path,False,image_shape[2:], 64)\n",
    "        \n",
    "        train_loss,total_samples,train_correct = cal_train(train_loader,device,model,criterion,optimizer)\n",
    "        train_loss /= total_samples\n",
    "        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Calculating accuracy and loss for test and validataion data\n",
    "        # val_acc, val_loss = evaluate(device, valid_loader, model)\n",
    "        # test_acc, test_loss = evaluate(device, test_loader, model)\n",
    "        print('\\nEpoch ', epoch+1, 'train_acc', train_acc, 'train_loss', train_loss)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40d1911-2ec1-4ba9-8a70-75fe4210f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [05:26<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1 train_acc 22.5153 train_loss 0.03443132845934279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = googlenet(weights=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 10  # Number of classes in iNaturalist dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description = \"Fine tuning on google net model\")\n",
    "# parser.add_argument('-s','--strategy',default=1, required=False,metavar=\"\",type=int,help='[0:freeze_all, 1:fine_tuning_all, 2:layer_wise_fine_tuning]')\n",
    "# parser.add_argument('-e','--epochs',default=5, required=False,metavar=\"\",type=int,help='number of epochs')\n",
    "# args = parser.parse_args()\n",
    "# epochs = args.epochs\n",
    "# strategy = args.strategy\n",
    "epochs=5\n",
    "train_fine_tune(model,epochs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61caf59-7b39-423d-9e14-d6caaa26a263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805a5c0-6e4b-4707-a1c8-7b141c9d549a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfe7c2-6567-4e64-a62c-05c5e6845aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
